{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# 검색 결과 첫 페이지 scraping\n",
    "first_url = 'https://search.naver.com/search.naver?where=news&query=%22%EC%BD%94%EB%A1%9C%EB%82%98%20%EB%B0%B1%EC%8B%A0%20%EB%B6%80%EC%9E%91%EC%9A%A9%22&sm=tab_opt&sort=0&photo=0&field=0&pd=6&ds=&de=&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3A6m&is_sug_officeid=0'\n",
    "first_r = requests.get(first_url)\n",
    "\n",
    "soup = BeautifulSoup(first_r.text, 'lxml')\n",
    "press_lst = soup.find_all('a', attrs={'class':'info press'})\n",
    "news_lst = soup.find_all('a', attrs={'class':'news_tit'})\n",
    "news_info = [(press.text.replace(\"언론사 선정\", \"\"), news.get('title'), news.get('href')) for press, news in zip(press_lst, news_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과 두 번째 페이지~마지막 페이지 scraping\n",
    "url = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%22%EC%BD%94%EB%A1%9C%EB%82%98%20%EB%B0%B1%EC%8B%A0%20%EB%B6%80%EC%9E%91%EC%9A%A9%22&sort=0&photo=0&field=0&pd=6&ds=2021.05.29&de=2021.11.25&cluster_rank=21&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:6m,a:all&start='\n",
    "\n",
    "for i in range(11, 311, 10):\n",
    "    new_url = url + str(i)\n",
    "    \n",
    "    r = requests.get(new_url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    press_lst = soup.find_all('a', attrs={'class':'info press'})\n",
    "    news_lst = soup.find_all('a', attrs={'class':'news_tit'})\n",
    "    info = [(press.text.replace(\"언론사 선정\", \"\"), news.get('title'), news.get('href')) for press, news in zip(press_lst, news_lst)]\n",
    "    news_info.extend(info)\n",
    "    \n",
    "news_info_df = pd.DataFrame(news_info, columns=['press', 'title', 'url'])\n",
    "news_info_df.drop_duplicates(inplace=True)\n",
    "news_info_df.to_csv('covid_side_effects_news.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미스터리, 픽션\n"
     ]
    }
   ],
   "source": [
    "# Google Crawling\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.google.com/search?q=isbn+038080722X&oq=isbn+038080722X&aqs=chrome..69i57.14638j0j7&sourceid=chrome&ie=UTF-8'\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.62 Safari/537.36'}\n",
    "res = requests.get(url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "book_info = soup.find_all('span', attrs={'class':\"w8qArf\"})\n",
    "for info in book_info:\n",
    "    if '장르' in info.text:\n",
    "        print(info.next_sibling.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "793d4bdf4aa091947cd8281459d6e8fe833d5ec676b0ac200c31417438349ef7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('condaenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
